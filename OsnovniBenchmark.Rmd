---
title: "Osnovni Benchmark model"
author: "Tomas Rode"
date: "30. 3. 2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidymodels)
library(tsibble)
library(dplyr)
library(readr)
library(lubridate)
library(stats)
library(ggplot2)
library(plotly)
library(timetk)
library(modeltime)
library(modeltime.ensemble)
library(parsnip)
library(forecast)


memory.limit(size=56000)
```

## Ponovna predstavitev podaktkov, za namene modeliranja

Ker ima R nekatere zelo atraktivne pakete za enostavno delo s časovnimi vrstami, sem se odločil, da svoje delo za trenutek nadaljujem v R okolju. Tu bom naredil prvi model, ki bo služil kot izhodišče za primerjavo z nadaljnimi modeli.


```{r, include=FALSE}
data_all_combined <- read.csv('data/data_all_combined_1h.csv') %>% 
  mutate(DateTime = ymd_hms(datetime)) %>% distinct(DateTime, .keep_all = TRUE) %>% select(-datetime) %>%
  as_tsibble %>% fill_gaps() %>% fill(ELCE, .direction = "down")
```

Zdaj naredimo sezonsko dekompozicijo časovne vrste.

```{r}
data_all_combined$ELCE %>% msts( seasonal.periods = c(24, 24*7, 24*365)) %>% mstl() %>% autoplot()
```


## Benchmark 1 in 2

Prva modela, ki ju bomo prezkusili za napovedovanje odjema sta modela sezonske dekompozicije, kjer bomo vsako od zgornjih sezonskih komponent modelirali z dvema metodama - eksponentnim glajenjem in arima modelom.

```{r}

splits <- initial_time_split(data_all_combined, prop = 0.85)

decomp_model_ets <- seasonal_reg(
  mode = "regression",
  seasonal_period_1 = 24,
  seasonal_period_2 = 7*24,
  seasonal_period_3 = 365*24
) %>% set_engine("stlm_ets") %>% fit(formula = ELCE ~ DateTime, data=training(splits))

decomp_model_arima <- seasonal_reg(
  mode = "regression",
  seasonal_period_1 = 24,
  seasonal_period_2 = 7*24,
  seasonal_period_3 = 365*24
) %>% set_engine("stlm_arima") %>% fit(formula = ELCE ~ DateTime, data=training(splits))

models_tbl <- modeltime_table(
    decomp_model_ets,
    decomp_model_arima
)


forecast_tbl <-  models_tbl %>%
    modeltime_forecast(new_data = testing(splits),
                       quiet = FALSE)

actual_tbl <- data_all_combined %>% tail(1000*24) %>%
  mutate(.model_id = 0, .model_desc = "Actual", .key = "Actual") %>%
  rename(.index = DateTime, .value = ELCE)

forecast_tbl_all <- rbind(forecast_tbl, actual_tbl)

forecast_tbl_all %>%
  plot_modeltime_forecast(.conf_interval_show = FALSE ,.interactive = TRUE)
  

```




Zdi se, da model morda ujame neke osnovne lastnosti sezonskosti, vseno pa se zdi povprečje nekoliko preveč statično in ob začetni precenitvi odjema napako ponavljamo skozi celotno preostalo obdobje. Opazimo tudi, da nama oba modela dajeta zelo podobne rezultate, kar je verjetno posledica enake specifikacije sezonskosti, kakor tudi optimizacije na enaki učni množici.

Za ocenjevanje modelov bom uporabil metriki MAPE in MAE, kjer bom vzel povprečja, dobljena pri navzkrižnem preverjanju na časovnih vrstah (kjer bomo za različna izhodišča napovedi vzeli 12 zadnjih mesecev).

```{r}
data_cv <- data.frame(data_all_combined) %>% time_series_cv(initial = "6 years, 4 months", assess = "1 month", skip="1 month")
```


```{r}
data_cv %>% plot_time_series_cv_plan(
        DateTime, ELCE, # date variable and value variable
        # Additional arguments passed to plot_time_series(),
        .facet_ncol = 4,
        .line_alpha = 0.5,
        .interactive = FALSE
    )
```



```{r, echo=TRUE, results='hide', warning=FALSE, message=FALSE}

cross_validation <- models_tbl %>%
    modeltime_fit_resamples(
        resamples = data_cv,
        control   = control_resamples(verbose = TRUE)
    )

```


## Primerjava obeh modelov

Zdi se, da je glede na vse izbrane metrike ARIMA model marginalno boljši. To potrjujeta tudi spodnji tabeli, kjer se osredotočimo na MAE in MAPE. Kljub vsemu je potrebno poudariti, da so pri eksponentnem glajenju rezultati nekoliko bolj konstantni, saj se minimalna in maksimalna napaka manj razlikujeta. 

```{r}
cross_validation %>%
    plot_modeltime_resamples(
      .metric_set = metric_set(mae, mape, mase, rmse),
      .point_size  = 3, 
      .point_alpha = 0.8,
      .interactive = FALSE
    )
```



```{r}
cross_validation %>%
    modeltime_resample_accuracy(metric_set=metric_set(mae),
                                summary_fns = c(mean=mean, min=min, max=max)) %>%
    table_modeltime_accuracy(.interactive = FALSE)
```

```{r}
cross_validation %>%
    modeltime_resample_accuracy(metric_set=metric_set(mape),
                                summary_fns = c(mean=mean, min=min, max=max)) %>%
    table_modeltime_accuracy(.interactive = FALSE)
```

